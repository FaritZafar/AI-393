

AI Project Report
Submitted to: Sir Farooq Zaidi 
Submitted By: Farit Ali Zafar (63095)
Sumair Ansar (63006)
Ali Naeem Sheikh (62053)

Group Leader - Farit Ali Zafar

KNN:
The KNN is k-nearest neighbors’ algorithm it is a most unique and simple algo it is also used in machine learning so we can used for both the problems known as classification and regression. The most unique part it is easy to implement and easy to get. But it has a issue it is slow and the size of the data use to grows.

Example:
The most common and unique example of KNN is voting system. We can convert it into sub classes and functions like “Vote” and “Not vote”.

SVM:
It is known as support vector machines it is the most solid reliable and observable machine learning algorithm which is used for both function classification and regression. But for most of the time it is used for the classification problems. It got some unique and professional way of in hence implementation as revision to other machine learning algorithm.


Example:
SVM related example is drawing a straight line in between two unique classes. Each and every data you write will go on the one side which is label as one class the rest points went on the other side known as secondary class.

MultinomialNB:
The MultinomialNB Naïve Bayes Classifer is a machine learning model basically used for large amount of data and good for the use of classification with some new techniques of discrete features. If we take MultinomialNB distribution it normally requires numeric count.

Weighted SVM:
Weighted SVM represent this hyper plane to give the coordinates of the vector. These are coefficients given by SVM.
AS I read and my understanding first coordinate is used for separation, W will be of the form (x, 0) where x is some non-zero number and then |x|>0.
SVM is an observed machine learning algorithm which and it is used for the purpose of classification and regression issues.


Weighted KNN:
AS we read in the class and (k-NN) is a relatively simple technique to analyze the class of an item based on two or more numeric predictor variables. We can say that for example a person based on his age, annual income, gender, years of education and so on. 
Other factor that I notice one amongst the various problems that have an effect on the performance of KNN formula is that the selection of the hyper parameter k. If k is simply too tiny, the formula would be additional sensitive to information points that area unit outliers.

Weighted Multinomial NB:
This method is used multiple times continuously on different platforms of a dataset and it is set to be implement for online learning. 
When we goes for a big data set this is mostly used for that because it fits for big data memory.
This algorithm have some unique performance purposes it is mainly used for big data which easily have possible overhead.

Discription of important parts of your .py file. 
We have used libraries which we have learned in lab class as well as theory class. In KNN,SVM,MultinomialNB we have used the code with the help of lab class and the one which Sir have helped us with and demonstrated. We have implemented the code with a help of our understanding.

Convulation is acheived by applying it again and again on the test file untill our desired result it obtained i.e. maximum accuracy.

The contribtuion of myself (Farit) is that I have code the SVM, KNN and MultinomialNB and also the weighted code of all these algorithm i.e convulation of KNN, SVM and MultinomialKB in 5x5, 7x7 and 9x9 and also weighted convulation of KNN 5x5 , 7x7 , 9x9 ,SVM 5x5, 7x7, 9x9 and MultinomailNB 5x5, 7x7, 9x9, while Sumair Ansar has contribtuted with me in KNN7,7 , SVM7,7 and MultinomialNB 7,7 while on the other hand Ali Naeem has also contributed with me in KNN5,5 , SVM5,5 nad MultinomialNB5,5.

To achieve 1 accuracy we will need to use tensor flow and other deep learning techniques which we have not studied untill now.
